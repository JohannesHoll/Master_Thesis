{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri May 22 16:13:14 2020\n",
    "\n",
    "@author: victo\n",
    "\"\"\"\n",
    "\n",
    "###necessary libraries###\n",
    "import re\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# file where csv files lies\n",
    "path = r'C:\\Users\\victo\\Master_Thesis\\scraperproject\\daimler\\daimler_scraper\\spiders\\news'                     \n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     \n",
    "\n",
    "# read files to pandas frame\n",
    "list_of_files = []\n",
    "\n",
    "for filename in all_files:\n",
    "    list_of_files.append(pd.read_csv(filename, \n",
    "                                     sep=',', \n",
    "                                     encoding='cp1252',\n",
    "                                     header=None,\n",
    "                                     names=[\"url\", \"header\", \"release time\", \"article content\"]\n",
    "                                     )\n",
    "                         )\n",
    "\n",
    "# Concatenate all content of files into one DataFrame\n",
    "concatenate_list_of_files = pd.concat(list_of_files, \n",
    "                                      ignore_index=True, \n",
    "                                      axis=0,\n",
    "                                      )\n",
    "\n",
    "# removing duplicates\n",
    "cleaned_dataframe = concatenate_list_of_files.sort_values(by='url', ascending=False)\n",
    "cleaned_dataframe = cleaned_dataframe.drop_duplicates(subset=[\"url\"], keep='first', ignore_index=True)\n",
    "\n",
    "print(cleaned_dataframe)\n",
    "\n",
    "##formatting date column\n",
    "dates = []\n",
    "times = []\n",
    "regex = r'(.*)(((1[0-2]|0?[1-9])\\/(3[01]|[12][0-9]|0?[1-9])\\/(?:[0-9]{2})?[0-9]{2})|((Jan(uary)?|Feb(ruary)?|Mar(ch)?|Apr(il)?|May|Jun(e)?|Jul(y)?|Aug(ust)?|Sep(tember)?|Oct(ober)?|Nov(ember)?|Dec(ember)?)\\s+\\d{1,2},\\s+\\d{4}))'\n",
    "regex2 = r'((1[0-2]|0?[1-9]):([0-5][0-9]) ?([AaPp][Mm]))'\n",
    "\n",
    "for date in cleaned_dataframe['release time']:\n",
    "    matches = re.finditer(regex, date)\n",
    "    for m in matches:\n",
    "        date = m.group()\n",
    "        date_formatted = date.replace(date[:2], '')\n",
    "        convert_date = datetime.strptime(date_formatted, '%B %d, %Y')\n",
    "        final_date = datetime.strftime(convert_date, \"%Y-%m-%d\")\n",
    "        print(final_date)\n",
    "        dates.append(final_date)\n",
    "\n",
    "for time in cleaned_dataframe['release time']:\n",
    "    matches = re.finditer(regex2, time)\n",
    "    for t in matches:\n",
    "        time = t.group()\n",
    "        convert_time = datetime.strptime(time, '%I:%M %p')\n",
    "        time_formatted = datetime.strftime(convert_time, '%H:%M:%S')\n",
    "        print(time_formatted)\n",
    "        times.append(time_formatted)\n",
    "\n",
    "## adding modified date to data frame\n",
    "cleaned_dataframe['date'] = dates\n",
    "cleaned_dataframe['time'] = times\n",
    "cleaned_dataframe['formatted date'] = cleaned_dataframe['date'] + str(' ') + cleaned_dataframe['time']\n",
    "\n",
    "## dropping unnecessary columns\n",
    "del cleaned_dataframe['date']\n",
    "del cleaned_dataframe['time']\n",
    "\n",
    "# New words and values\n",
    "new_words = {'crushes': 10,\n",
    "             'beats': 5,\n",
    "             'misses': -5,\n",
    "             'trouble': -10,\n",
    "             'falls': -100,\n",
    "             }\n",
    "\n",
    "print('Start!')\n",
    "# Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "# Update the lexicon\n",
    "vader.lexicon.update(new_words)\n",
    "\n",
    "print('ok!')\n",
    "\n",
    "## analysis of article header\n",
    "score_header = []\n",
    "\n",
    "for header in cleaned_dataframe['header']:\n",
    "    polarity_score = vader.polarity_scores(header)\n",
    "    score_header.append(polarity_score)\n",
    "\n",
    "# Join the DataFrames\n",
    "cleaned_dataframe[['neg_vader_header',\n",
    "                   'neu_vader_header',\n",
    "                   'pos_vader_header',\n",
    "                   'compound_vader_header'\n",
    "                   ]] = pd.DataFrame(score_header)[['neg',\n",
    "                                                    'neu',\n",
    "                                                    'pos',\n",
    "                                                    'compound'\n",
    "                                                    ]]\n",
    "\n",
    "## analysis of article content\n",
    "score_content = []\n",
    "\n",
    "for articlecontent in cleaned_dataframe['article content']:\n",
    "    polarity_score = vader.polarity_scores(articlecontent)\n",
    "    score_content.append(polarity_score)\n",
    "\n",
    "# Join the DataFrames\n",
    "cleaned_dataframe[['neg_vader_articel_content',\n",
    "                   'neu_vader_articel_content',\n",
    "                   'pos_vader_articel_content',\n",
    "                   'compound_vader_articel_content'\n",
    "                   ]] = pd.DataFrame(score_content)[['neg',\n",
    "                                                     'neu',\n",
    "                                                     'pos',\n",
    "                                                     'compound'\n",
    "                                                     ]]\n",
    "\n",
    "print(cleaned_dataframe)\n",
    "\n",
    "## saving outcome of vader to csv\n",
    "current_date = datetime.today().strftime('%Y-%m-%d')\n",
    "cleaned_dataframe.to_csv(r'C:\\Users\\victo\\Master_Thesis\\semanticanalysis\\analysis_with_vader\\daimler\\outcome_using_vader\\outcome_of_vader_on_daimler_news_' + str(current_date) + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
