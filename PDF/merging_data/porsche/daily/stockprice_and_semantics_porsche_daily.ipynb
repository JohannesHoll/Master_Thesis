{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###necessary libraries\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from functools import reduce\n",
    "\n",
    "# file where csv files of flair analysis lies\n",
    "path_flair = r'C:\\Users\\victo\\Master_Thesis\\semanticanalysis\\analysis_with_flair\\porsche\\outcome_using_flair'\n",
    "all_files_flair = glob.glob(os.path.join(path_flair, \"*.csv\"))\n",
    "\n",
    "# read files to pandas frame\n",
    "list_of_files_flair = []\n",
    "\n",
    "for filename in all_files_flair:\n",
    "    list_of_files_flair.append(pd.read_csv(filename,\n",
    "                                           sep=',',\n",
    "                                           )\n",
    "                               )\n",
    "\n",
    "# Concatenate all content of files into one DataFrames\n",
    "concatenate_list_of_files_flair = pd.concat(list_of_files_flair,\n",
    "                                            ignore_index=True,\n",
    "                                            axis=0,\n",
    "                                            )\n",
    "\n",
    "# removing duplicates\n",
    "cleaned_dataframe_flair = concatenate_list_of_files_flair.sort_values(by='url', ascending=False)\n",
    "cleaned_dataframe_flair = cleaned_dataframe_flair.drop_duplicates(subset=[\"url\"], keep='first', ignore_index=True)\n",
    "\n",
    "print(cleaned_dataframe_flair)\n",
    "\n",
    "# file where csv files of vader analysis lies\n",
    "path_vader = r'C:\\Users\\victo\\Master_Thesis\\semanticanalysis\\analysis_with_vader\\porsche\\outcome_using_vader'\n",
    "all_files_vader = glob.glob(os.path.join(path_vader, \"*.csv\"))\n",
    "\n",
    "# read files to pandas frame\n",
    "list_of_files_vader = []\n",
    "\n",
    "for filename in all_files_vader:\n",
    "    list_of_files_vader.append(pd.read_csv(filename,\n",
    "                                           sep=',',\n",
    "                                           )\n",
    "                               )\n",
    "\n",
    "# Concatenate all content of files into one DataFrames\n",
    "concatenate_list_of_files_vader = pd.concat(list_of_files_vader,\n",
    "                                            ignore_index=True,\n",
    "                                            axis=0,\n",
    "                                            )\n",
    "\n",
    "# removing duplicates\n",
    "cleaned_dataframe_vader = concatenate_list_of_files_vader.sort_values(by='url', ascending=False)\n",
    "cleaned_dataframe_vader = cleaned_dataframe_vader.drop_duplicates(subset=[\"url\"], keep='first', ignore_index=True)\n",
    "\n",
    "print(cleaned_dataframe_vader)\n",
    "\n",
    "# file where csv files of textblob analysis lies\n",
    "path_textblob = r'C:\\Users\\victo\\Master_Thesis\\semanticanalysis\\analysis_with_textblob\\porsche\\outcome_using_texblob'\n",
    "all_files_textblob = glob.glob(os.path.join(path_textblob, \"*.csv\"))\n",
    "\n",
    "# read files to pandas frame\n",
    "list_of_files_textblob = []\n",
    "\n",
    "for filename in all_files_textblob:\n",
    "    list_of_files_textblob.append(pd.read_csv(filename,\n",
    "                                              sep=',',\n",
    "                                              )\n",
    "                                  )\n",
    "\n",
    "# Concatenate all content of files into one DataFrames\n",
    "concatenate_list_of_files_textblob = pd.concat(list_of_files_textblob,\n",
    "                                               ignore_index=True,\n",
    "                                               axis=0,\n",
    "                                               )\n",
    "\n",
    "# removing duplicates\n",
    "cleaned_dataframe_textblob = concatenate_list_of_files_textblob.sort_values(by='url', ascending=False)\n",
    "cleaned_dataframe_textblob = cleaned_dataframe_textblob.drop_duplicates(subset=[\"url\"], keep='first', ignore_index=True)\n",
    "\n",
    "print(cleaned_dataframe_textblob)\n",
    "\n",
    "##merging files together\n",
    "merged_df = pd.merge(cleaned_dataframe_flair, cleaned_dataframe_vader, on=['url']) #,'header','release time','article content','formatted date'])\n",
    "merged_df = pd.merge(merged_df, cleaned_dataframe_textblob, on=['url'])#,'header','release time','article content','formatted date'])\n",
    "merged_df['formatted date'] = pd.to_datetime(merged_df['formatted date'])\n",
    "merged_df.rename(columns={'formatted date': 'formatteddate'}, inplace=True)\n",
    "\n",
    "#importing of stock price files\n",
    "path_stockprices = r'C:\\Users\\victo\\Master_Thesis\\stockprice_data\\porsche\\daily_stockpricefiles_with_return'\n",
    "\n",
    "##filling empty cells with 0\n",
    "#merged_df[['flair_sentiment_header_score', 'flair_sentiment_content_score', 'neg_vader_header', 'neu_vader_header',\n",
    "#           'pos_vader_header', 'compound_vader_header', 'neg_vader_articel_content', 'neu_vader_articel_content',\n",
    "#           'pos_vader_articel_content', 'compound_vader_articel_content', 'polarity_textblob_sentiment_header',\n",
    "#           'subjectivity_textblob_sentiment_header', 'polarity_textblob_sentiment_content',\n",
    "#           'subjectivity_textblob_sentiment_content'\n",
    "#           ]] = merged_df[['flair_sentiment_header_score', 'flair_sentiment_content_score', 'neg_vader_header', 'neu_vader_header',\n",
    "#                           'pos_vader_header', 'compound_vader_header', 'neg_vader_articel_content',\n",
    "#                           'neu_vader_articel_content', 'pos_vader_articel_content', 'compound_vader_articel_content',\n",
    "#                           'polarity_textblob_sentiment_header', 'subjectivity_textblob_sentiment_header',\n",
    "#                           'polarity_textblob_sentiment_content', 'subjectivity_textblob_sentiment_content'\n",
    "#                           ]].fillna(0)\n",
    "\n",
    "#creating new column with formatted date\n",
    "dates = []\n",
    "for date in merged_df['formatteddate']:\n",
    "    matches = re.search('\\d{4}-\\d{2}-\\d{2}', str(date))\n",
    "    date_merged = matches.group()\n",
    "    dates.append(date_merged)\n",
    "\n",
    "merged_df['Date'] = dates\n",
    "print(merged_df.Date)\n",
    "\n",
    "# new dataframe for merging later with stockprices\n",
    "dates_merger = []\n",
    "flair_sentiment_header_score = []\n",
    "flair_sentiment_content_score = []\n",
    "compound_vader_header = []\n",
    "compound_vader_articel_content = []\n",
    "polarity_textblob_sentiment_header = []\n",
    "polarity_textblob_sentiment_content = []\n",
    "\n",
    "for dates in merged_df['formatteddate']:\n",
    "    matches2 = re.search('\\d{4}-\\d{2}-\\d{2}', str(dates))\n",
    "    date_merged2 = matches2.group()\n",
    "    for index, row in merged_df.iterrows():\n",
    "        if row['Date'] == date_merged2:\n",
    "            dates_merger.append(row['Date'])\n",
    "            #print(row['Date'])\n",
    "            flair_sentiment_header_score.append(row['flair_sentiment_header_score'])\n",
    "            #print(row['flair_sentiment_header_score'])\n",
    "            flair_sentiment_content_score.append(row['flair_sentiment_content_score'])\n",
    "            #print(row['flair_sentiment_content_score'])\n",
    "            compound_vader_header.append(row['compound_vader_header'])\n",
    "            #print(row['compound_vader_header'])\n",
    "            compound_vader_articel_content.append(row['compound_vader_articel_content'])\n",
    "            #print(row['compound_vader_articel_content'])\n",
    "            polarity_textblob_sentiment_header.append(row['polarity_textblob_sentiment_header'])\n",
    "            #print(row['polarity_textblob_sentiment_header'])\n",
    "            polarity_textblob_sentiment_content.append(row['polarity_textblob_sentiment_content'])\n",
    "            #print(row['polarity_textblob_sentiment_content'])\n",
    "\n",
    "merge_list = list(zip(dates_merger,\n",
    "                      flair_sentiment_header_score,\n",
    "                      flair_sentiment_content_score,\n",
    "                      compound_vader_header,\n",
    "                      compound_vader_articel_content,\n",
    "                      polarity_textblob_sentiment_header,\n",
    "                      polarity_textblob_sentiment_content))\n",
    "\n",
    "new_merged_df = pd.DataFrame(data=merge_list,\n",
    "                             columns=['Date',\n",
    "                                      'flair_sentiment_header_score',\n",
    "                                      'flair_sentiment_content_score',\n",
    "                                      'compound_vader_header',\n",
    "                                      'compound_vader_articel_content',\n",
    "                                      'polarity_textblob_sentiment_header',\n",
    "                                      'polarity_textblob_sentiment_content']\n",
    "                             )\n",
    "\n",
    "#new_merged_df['Date'] = pd.to_datetime(new_merged_df['Date'])\n",
    "\n",
    "new_merged_df = new_merged_df.groupby('Date').mean()\n",
    "\n",
    "print(new_merged_df)\n",
    "\n",
    "for file in glob.iglob(path_stockprices + '\\*.csv'):\n",
    "    df_daily_stock_prices = pd.read_csv(file,\n",
    "                                        sep=',',\n",
    "                                        )\n",
    "\n",
    "    new_df_daily_stockprices = df_daily_stock_prices.merge(new_merged_df,\n",
    "                                                           left_on='Date',\n",
    "                                                           right_on='Date',\n",
    "                                                           how='left')\n",
    "\n",
    "    new_df_daily_stockprices.to_csv(r'C:\\Users\\victo\\Master_Thesis\\merging_data\\porsche\\daily\\merged_files\\daily_porscheprices_with_semantics_.csv', index=False)\n",
    "    print('File has been saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
