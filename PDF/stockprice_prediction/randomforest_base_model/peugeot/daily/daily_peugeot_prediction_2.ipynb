{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###necessary libaries###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seglearn.transform import FeatureRep, SegmentXYForecast, last\n",
    "from subprocess import check_output\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Flatten\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import newaxis\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import math\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ParameterSampler, ParameterGrid\n",
    "\n",
    "model_seed = 100\n",
    "# ensure same output results\n",
    "seed(101)\n",
    "tf.random.set_seed(model_seed)\n",
    "\n",
    "# file where csv files lies\n",
    "path = r'C:\\Users\\victo\\Master_Thesis\\merging_data\\peugeot\\daily\\merged_files'\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "# read files to pandas frame\n",
    "list_of_files = []\n",
    "\n",
    "for filename in all_files:\n",
    "    list_of_files.append(pd.read_csv(filename,\n",
    "                                     sep=',',\n",
    "                                     )\n",
    "                         )\n",
    "\n",
    "# Concatenate all content of files into one DataFrames\n",
    "concatenate_dataframe = pd.concat(list_of_files,\n",
    "                                  ignore_index=True,\n",
    "                                  axis=0,\n",
    "                                  )\n",
    "\n",
    "# print(concatenate_dataframe)\n",
    "\n",
    "new_df_flair_content = concatenate_dataframe[['OPEN',\n",
    "                                              'HIGH',\n",
    "                                              'LOW',\n",
    "                                              'CLOSE',\n",
    "                                              'VOLUME',\n",
    "                                              'flair_sentiment_content_score']]\n",
    "\n",
    "new_df_flair_content = new_df_flair_content.fillna(0)\n",
    "# new_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'compound_vader_articel_content']].astype(np.float64)\n",
    "# print(new_df)\n",
    "\n",
    "# train, valid, test split\n",
    "valid_test_size_split_flair_content = 0.1\n",
    "\n",
    "X_train_flair_content, \\\n",
    "X_else_flair_content, \\\n",
    "y_train_flair_content, \\\n",
    "y_else_flair_content = train_test_split(new_df_flair_content,\n",
    "                                        new_df_flair_content['OPEN'],\n",
    "                                        test_size=valid_test_size_split_flair_content*2,\n",
    "                                        shuffle=False)\n",
    "\n",
    "X_valid_flair_content, \\\n",
    "X_test_flair_content, \\\n",
    "y_valid_flair_content, \\\n",
    "y_test_flair_content = train_test_split(X_else_flair_content,\n",
    "                                        y_else_flair_content,\n",
    "                                        test_size=0.5,\n",
    "                                        shuffle=False)\n",
    "#print(y_else)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "# normalize data\n",
    "def minmax_scale_flair_content(df_x, series_y, normalizers_flair_content = None):\n",
    "    features_to_minmax = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'flair_sentiment_content_score']\n",
    "\n",
    "    if not normalizers_flair_content:\n",
    "        normalizers_flair_content = {}\n",
    "\n",
    "    for feat in features_to_minmax:\n",
    "        if feat not in normalizers_flair_content:\n",
    "            normalizers_flair_content[feat] = MinMaxScaler()\n",
    "            normalizers_flair_content[feat].fit(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "        df_x[feat] = normalizers_flair_content[feat].transform(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "    series_y = normalizers_flair_content['OPEN'].transform(series_y.values.reshape(-1, 1))\n",
    "\n",
    "    return df_x, series_y, normalizers_flair_content\n",
    "\n",
    "X_train_norm_flair_content, \\\n",
    "y_train_norm_flair_content, \\\n",
    "normalizers_flair_content = minmax_scale_flair_content(X_train_flair_content,\n",
    "                                                       y_train_flair_content\n",
    "                                                       )\n",
    "\n",
    "X_valid_norm_flair_content, \\\n",
    "y_valid_norm_flair_content, \\\n",
    "_ = minmax_scale_flair_content(X_valid_flair_content,\n",
    "                               y_valid_flair_content,\n",
    "                               normalizers_flair_content=normalizers_flair_content\n",
    "                               )\n",
    "\n",
    "X_test_norm_flair_content, \\\n",
    "y_test_norm_flair_content, \\\n",
    "_ = minmax_scale_flair_content(X_test_flair_content,\n",
    "                               y_test_flair_content,\n",
    "                               normalizers_flair_content=normalizers_flair_content\n",
    "                               )\n",
    "\n",
    "# Creating target (y) and \"windows\" (X) for modeling\n",
    "TIME_WINDOW_flair_content = 30\n",
    "FORECAST_DISTANCE_flair_content = 5\n",
    "\n",
    "segmenter_flair_content = SegmentXYForecast(width=TIME_WINDOW_flair_content,\n",
    "                                            step=1,\n",
    "                                            y_func=last,\n",
    "                                            forecast=FORECAST_DISTANCE_flair_content\n",
    "                                            )\n",
    "\n",
    "X_train_rolled_flair_content, \\\n",
    "y_train_rolled_flair_content, \\\n",
    "_ = segmenter_flair_content.fit_transform([X_train_norm_flair_content.values],\n",
    "                                          [y_train_norm_flair_content.flatten()]\n",
    "                                          )\n",
    "\n",
    "X_valid_rolled_flair_content, \\\n",
    "y_valid_rolled_flair_content, \\\n",
    "_ = segmenter_flair_content.fit_transform([X_valid_norm_flair_content.values],\n",
    "                                          [y_valid_norm_flair_content.flatten()]\n",
    "                                          )\n",
    "\n",
    "X_test_rolled_flair_content, \\\n",
    "y_test_rolled_flair_content, \\\n",
    "_ = segmenter_flair_content.fit_transform([X_test_norm_flair_content.values],\n",
    "                                          [y_test_norm_flair_content.flatten()]\n",
    "                                          )\n",
    "\n",
    "shape_flair_content = X_train_rolled_flair_content.shape\n",
    "X_train_flattened_flair_content = X_train_rolled_flair_content.reshape(shape_flair_content[0],\n",
    "                                                                       shape_flair_content[1]*shape_flair_content[2]\n",
    "                                                                       )\n",
    "\n",
    "X_train_flattened_flair_content.shape\n",
    "shape_flair_content = X_valid_rolled_flair_content.shape\n",
    "X_valid_flattened = X_valid_rolled_flair_content.reshape(shape_flair_content[0],\n",
    "                                                         shape_flair_content[1]*shape_flair_content[2]\n",
    "                                                         )\n",
    "\n",
    "# Random Forest\n",
    "N_ESTIMATORS_flair_content = 30\n",
    "RANDOM_STATE_flair_content = 452543634\n",
    "\n",
    "RF_base_model_flair_content = RandomForestRegressor(random_state=RANDOM_STATE_flair_content,\n",
    "                                                    n_estimators=N_ESTIMATORS_flair_content,\n",
    "                                                    n_jobs=-1,\n",
    "                                                    verbose=100\n",
    "                                                    )\n",
    "\n",
    "RF_base_model_flair_content.fit(X_train_flattened_flair_content, y_train_rolled_flair_content)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_flair_content = RF_base_model_flair_content.predict(X_valid_flattened)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "rms_base_flair_content = sqrt(mean_squared_error(y_valid_rolled_flair_content,\n",
    "                                                 RF_base_model_predictions_flair_content\n",
    "                                                 )\n",
    "                              )\n",
    "\n",
    "print(\"Root mean squared error on valid:\",rms_base_flair_content)\n",
    "print(\"Root mean squared error on valid inverse transformed from normalization:\",normalizers_flair_content[\"OPEN\"]\n",
    "      .inverse_transform(np.array([rms_base_flair_content]).reshape(-1, 1)))\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_flair_content = normalizers_flair_content['OPEN']\\\n",
    "                                          .inverse_transform(np.array(RF_base_model_predictions_flair_content).reshape(-1, 1))\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "new_df_flair_header = concatenate_dataframe[['OPEN',\n",
    "                                             'HIGH',\n",
    "                                             'LOW',\n",
    "                                             'CLOSE',\n",
    "                                             'VOLUME',\n",
    "                                             'flair_sentiment_header_score']]\n",
    "\n",
    "new_df_flair_header = new_df_flair_header.fillna(0)\n",
    "# new_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'flair_sentiment_header_score']].astype(np.float64)\n",
    "# print(new_df)\n",
    "\n",
    "# train, valid, test split\n",
    "valid_test_size_split_flair_header = 0.1\n",
    "\n",
    "X_train_flair_header, \\\n",
    "X_else_flair_header, \\\n",
    "y_train_flair_header, \\\n",
    "y_else_flair_header = train_test_split(new_df_flair_header,\n",
    "                                       new_df_flair_header['OPEN'],\n",
    "                                       test_size=valid_test_size_split_flair_header*2,\n",
    "                                       shuffle=False)\n",
    "\n",
    "X_valid_flair_header, \\\n",
    "X_test_flair_header, \\\n",
    "y_valid_flair_header, \\\n",
    "y_test_flair_header = train_test_split(X_else_flair_header,\n",
    "                                       y_else_flair_header,\n",
    "                                       test_size=0.5,\n",
    "                                       shuffle=False)\n",
    "#print(y_else)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "# normalize data\n",
    "def minmax_scale_flair_header(df_x, series_y, normalizers_flair_header = None):\n",
    "    features_to_minmax = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'flair_sentiment_header_score']\n",
    "\n",
    "    if not normalizers_flair_header:\n",
    "        normalizers_flair_header = {}\n",
    "\n",
    "    for feat in features_to_minmax:\n",
    "        if feat not in normalizers_flair_header:\n",
    "            normalizers_flair_header[feat] = MinMaxScaler()\n",
    "            normalizers_flair_header[feat].fit(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "        df_x[feat] = normalizers_flair_header[feat].transform(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "    series_y = normalizers_flair_header['OPEN'].transform(series_y.values.reshape(-1, 1))\n",
    "\n",
    "    return df_x, series_y, normalizers_flair_header\n",
    "\n",
    "X_train_norm_flair_header, \\\n",
    "y_train_norm_flair_header, \\\n",
    "normalizers_flair_header = minmax_scale_flair_header(X_train_flair_header,\n",
    "                                                     y_train_flair_header\n",
    "                                                     )\n",
    "\n",
    "X_valid_norm_flair_header, \\\n",
    "y_valid_norm_flair_header, \\\n",
    "_ = minmax_scale_flair_header(X_valid_flair_header,\n",
    "                              y_valid_flair_header,\n",
    "                              normalizers_flair_header=normalizers_flair_header\n",
    "                              )\n",
    "\n",
    "X_test_norm_flair_header, \\\n",
    "y_test_norm_flair_header, \\\n",
    "_ = minmax_scale_flair_header(X_test_flair_header,\n",
    "                              y_test_flair_header,\n",
    "                              normalizers_flair_header=normalizers_flair_header\n",
    "                              )\n",
    "\n",
    "# Creating target (y) and \"windows\" (X) for modeling\n",
    "TIME_WINDOW_flair_header = 30\n",
    "FORECAST_DISTANCE_flair_header = 5\n",
    "\n",
    "segmenter_flair_header = SegmentXYForecast(width=TIME_WINDOW_flair_header,\n",
    "                                           step=1,\n",
    "                                           y_func=last,\n",
    "                                           forecast=FORECAST_DISTANCE_flair_header\n",
    "                                           )\n",
    "\n",
    "X_train_rolled_flair_header, \\\n",
    "y_train_rolled_flair_header, \\\n",
    "_ = segmenter_flair_header.fit_transform([X_train_norm_flair_header.values],\n",
    "                                         [y_train_norm_flair_header.flatten()]\n",
    "                                         )\n",
    "\n",
    "X_valid_rolled_flair_header, \\\n",
    "y_valid_rolled_flair_header, \\\n",
    "_ = segmenter_flair_header.fit_transform([X_valid_norm_flair_header.values],\n",
    "                                         [y_valid_norm_flair_header.flatten()]\n",
    "                                         )\n",
    "\n",
    "X_test_rolled_flair_header, \\\n",
    "y_test_rolled_flair_header, \\\n",
    "_ = segmenter_flair_header.fit_transform([X_test_norm_flair_header.values],\n",
    "                                         [y_test_norm_flair_header.flatten()]\n",
    "                                         )\n",
    "\n",
    "shape_flair_header = X_train_rolled_flair_header.shape\n",
    "X_train_flattened_flair_header = X_train_rolled_flair_header.reshape(shape_flair_header[0],\n",
    "                                                                     shape_flair_header[1]*shape_flair_header[2]\n",
    "                                                                     )\n",
    "\n",
    "X_train_flattened_flair_header.shape\n",
    "shape_flair_header = X_valid_rolled_flair_header.shape\n",
    "X_valid_flattened = X_valid_rolled_flair_header.reshape(shape_flair_header[0],\n",
    "                                                        shape_flair_header[1]*shape_flair_header[2]\n",
    "                                                        )\n",
    "\n",
    "# Random Forest\n",
    "N_ESTIMATORS_flair_header = 30\n",
    "RANDOM_STATE_flair_header = 452543634\n",
    "\n",
    "RF_base_model_flair_header = RandomForestRegressor(random_state=RANDOM_STATE_flair_header,\n",
    "                                                   n_estimators=N_ESTIMATORS_flair_header,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   verbose=100\n",
    "                                                   )\n",
    "\n",
    "RF_base_model_flair_header.fit(X_train_flattened_flair_header, y_train_rolled_flair_header)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_flair_header = RF_base_model_flair_header.predict(X_valid_flattened)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "rms_base_flair_header = sqrt(mean_squared_error(y_valid_rolled_flair_header,\n",
    "                                                RF_base_model_predictions_flair_header\n",
    "                                                )\n",
    "                             )\n",
    "\n",
    "print(\"Root mean squared error on valid:\",rms_base_flair_header)\n",
    "print(\"Root mean squared error on valid inverse transformed from normalization:\",normalizers_flair_header[\"OPEN\"]\n",
    "      .inverse_transform(np.array([rms_base_flair_header]).reshape(-1, 1)))\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_flair_header = normalizers_flair_header['OPEN']\\\n",
    "                                          .inverse_transform(np.array(RF_base_model_predictions_flair_header).reshape(-1, 1))\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "new_df_textblob_content = concatenate_dataframe[['OPEN',\n",
    "                                                 'HIGH',\n",
    "                                                 'LOW',\n",
    "                                                 'CLOSE',\n",
    "                                                 'VOLUME',\n",
    "                                                 'polarity_textblob_sentiment_content']]\n",
    "\n",
    "new_df_textblob_content = new_df_textblob_content.fillna(0)\n",
    "# new_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'polarity_textblob_sentiment_content']].astype(np.float64)\n",
    "# print(new_df)\n",
    "\n",
    "# train, valid, test split\n",
    "valid_test_size_split_textblob_content = 0.1\n",
    "\n",
    "X_train_textblob_content, \\\n",
    "X_else_textblob_content, \\\n",
    "y_train_textblob_content, \\\n",
    "y_else_textblob_content = train_test_split(new_df_textblob_content,\n",
    "                                           new_df_textblob_content['OPEN'],\n",
    "                                           test_size=valid_test_size_split_textblob_content*2,\n",
    "                                           shuffle=False)\n",
    "\n",
    "X_valid_textblob_content, \\\n",
    "X_test_textblob_content, \\\n",
    "y_valid_textblob_content, \\\n",
    "y_test_textblob_content = train_test_split(X_else_textblob_content,\n",
    "                                           y_else_textblob_content,\n",
    "                                           test_size=0.5,\n",
    "                                           shuffle=False)\n",
    "#print(y_else)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "# normalize data\n",
    "def minmax_scale_textblob_content(df_x, series_y, normalizers_textblob_content = None):\n",
    "    features_to_minmax = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'polarity_textblob_sentiment_content']\n",
    "\n",
    "    if not normalizers_textblob_content:\n",
    "        normalizers_textblob_content = {}\n",
    "\n",
    "    for feat in features_to_minmax:\n",
    "        if feat not in normalizers_textblob_content:\n",
    "            normalizers_textblob_content[feat] = MinMaxScaler()\n",
    "            normalizers_textblob_content[feat].fit(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "        df_x[feat] = normalizers_textblob_content[feat].transform(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "    series_y = normalizers_textblob_content['OPEN'].transform(series_y.values.reshape(-1, 1))\n",
    "\n",
    "    return df_x, series_y, normalizers_textblob_content\n",
    "\n",
    "X_train_norm_textblob_content, \\\n",
    "y_train_norm_textblob_content, \\\n",
    "normalizers_textblob_content = minmax_scale_textblob_content(X_train_textblob_content,\n",
    "                                                             y_train_textblob_content\n",
    "                                                             )\n",
    "\n",
    "X_valid_norm_textblob_content, \\\n",
    "y_valid_norm_textblob_content, \\\n",
    "_ = minmax_scale_textblob_content(X_valid_textblob_content,\n",
    "                                  y_valid_textblob_content,\n",
    "                                  normalizers_textblob_content=normalizers_textblob_content\n",
    "                                  )\n",
    "\n",
    "X_test_norm_textblob_content, \\\n",
    "y_test_norm_textblob_content, \\\n",
    "_ = minmax_scale_textblob_content(X_test_textblob_content,\n",
    "                                  y_test_textblob_content,\n",
    "                                  normalizers_textblob_content=normalizers_textblob_content\n",
    "                                  )\n",
    "\n",
    "# Creating target (y) and \"windows\" (X) for modeling\n",
    "TIME_WINDOW_textblob_content = 30\n",
    "FORECAST_DISTANCE_textblob_content = 5\n",
    "\n",
    "segmenter_textblob_content = SegmentXYForecast(width=TIME_WINDOW_textblob_content,\n",
    "                                               step=1,\n",
    "                                               y_func=last,\n",
    "                                               forecast=FORECAST_DISTANCE_textblob_content\n",
    "                                               )\n",
    "\n",
    "X_train_rolled_textblob_content, \\\n",
    "y_train_rolled_textblob_content, \\\n",
    "_ = segmenter_textblob_content.fit_transform([X_train_norm_textblob_content.values],\n",
    "                                             [y_train_norm_textblob_content.flatten()]\n",
    "                                             )\n",
    "\n",
    "X_valid_rolled_textblob_content, \\\n",
    "y_valid_rolled_textblob_content, \\\n",
    "_ = segmenter_textblob_content.fit_transform([X_valid_norm_textblob_content.values],\n",
    "                                             [y_valid_norm_textblob_content.flatten()]\n",
    "                                             )\n",
    "\n",
    "X_test_rolled_textblob_content, \\\n",
    "y_test_rolled_textblob_content, \\\n",
    "_ = segmenter_textblob_content.fit_transform([X_test_norm_textblob_content.values],\n",
    "                                             [y_test_norm_textblob_content.flatten()]\n",
    "                                             )\n",
    "\n",
    "shape_textblob_content = X_train_rolled_textblob_content.shape\n",
    "X_train_flattened_textblob_content = X_train_rolled_textblob_content.reshape(shape_textblob_content[0],\n",
    "                                                                             shape_textblob_content[1]*shape_textblob_content[2]\n",
    "                                                                             )\n",
    "\n",
    "X_train_flattened_textblob_content.shape\n",
    "shape_textblob_content = X_valid_rolled_textblob_content.shape\n",
    "X_valid_flattened = X_valid_rolled_textblob_content.reshape(shape_textblob_content[0],\n",
    "                                                            shape_textblob_content[1]*shape_textblob_content[2]\n",
    "                                                            )\n",
    "\n",
    "# Random Forest\n",
    "N_ESTIMATORS_textblob_content = 30\n",
    "RANDOM_STATE_textblob_content = 452543634\n",
    "\n",
    "RF_base_model_textblob_content = RandomForestRegressor(random_state=RANDOM_STATE_textblob_content,\n",
    "                                                       n_estimators=N_ESTIMATORS_textblob_content,\n",
    "                                                       n_jobs=-1,\n",
    "                                                       verbose=100\n",
    "                                                       )\n",
    "\n",
    "RF_base_model_textblob_content.fit(X_train_flattened_textblob_content, y_train_rolled_textblob_content)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_textblob_content = RF_base_model_textblob_content.predict(X_valid_flattened)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "rms_base_textblob_content = sqrt(mean_squared_error(y_valid_rolled_textblob_content,\n",
    "                                                    RF_base_model_predictions_textblob_content\n",
    "                                                    )\n",
    "                                 )\n",
    "\n",
    "print(\"Root mean squared error on valid:\",rms_base_textblob_content)\n",
    "print(\"Root mean squared error on valid inverse transformed from normalization:\",normalizers_textblob_content[\"OPEN\"]\n",
    "      .inverse_transform(np.array([rms_base_textblob_content]).reshape(-1, 1)))\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_textblob_content = normalizers_textblob_content['OPEN']\\\n",
    "                                          .inverse_transform(np.array(RF_base_model_predictions_textblob_content).reshape(-1, 1))\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "new_df_textblob_header = concatenate_dataframe[['OPEN',\n",
    "                                                'HIGH',\n",
    "                                                'LOW',\n",
    "                                                'CLOSE',\n",
    "                                                'VOLUME',\n",
    "                                                'polarity_textblob_sentiment_header']]\n",
    "\n",
    "new_df_textblob_header = new_df_textblob_header.fillna(0)\n",
    "# new_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'polarity_textblob_sentiment_header']].astype(np.float64)\n",
    "# print(new_df)\n",
    "\n",
    "# train, valid, test split\n",
    "valid_test_size_split_textblob_header = 0.1\n",
    "\n",
    "X_train_textblob_header, \\\n",
    "X_else_textblob_header, \\\n",
    "y_train_textblob_header, \\\n",
    "y_else_textblob_header = train_test_split(new_df_textblob_header,\n",
    "                                          new_df_textblob_header['OPEN'],\n",
    "                                          test_size=valid_test_size_split_textblob_header*2,\n",
    "                                          shuffle=False)\n",
    "\n",
    "X_valid_textblob_header, \\\n",
    "X_test_textblob_header, \\\n",
    "y_valid_textblob_header, \\\n",
    "y_test_textblob_header = train_test_split(X_else_textblob_header,\n",
    "                                          y_else_textblob_header,\n",
    "                                          test_size=0.5,\n",
    "                                          shuffle=False)\n",
    "#print(y_else)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "# normalize data\n",
    "def minmax_scale_textblob_header(df_x, series_y, normalizers_textblob_header = None):\n",
    "    features_to_minmax = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'polarity_textblob_sentiment_header']\n",
    "\n",
    "    if not normalizers_textblob_header:\n",
    "        normalizers_textblob_header = {}\n",
    "\n",
    "    for feat in features_to_minmax:\n",
    "        if feat not in normalizers_textblob_header:\n",
    "            normalizers_textblob_header[feat] = MinMaxScaler()\n",
    "            normalizers_textblob_header[feat].fit(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "        df_x[feat] = normalizers_textblob_header[feat].transform(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "    series_y = normalizers_textblob_header['OPEN'].transform(series_y.values.reshape(-1, 1))\n",
    "\n",
    "    return df_x, series_y, normalizers_textblob_header\n",
    "\n",
    "X_train_norm_textblob_header, \\\n",
    "y_train_norm_textblob_header, \\\n",
    "normalizers_textblob_header = minmax_scale_textblob_header(X_train_textblob_header,\n",
    "                                                           y_train_textblob_header\n",
    "                                                           )\n",
    "\n",
    "X_valid_norm_textblob_header, \\\n",
    "y_valid_norm_textblob_header, \\\n",
    "_ = minmax_scale_textblob_header(X_valid_textblob_header,\n",
    "                                 y_valid_textblob_header,\n",
    "                                 normalizers_textblob_header=normalizers_textblob_header\n",
    "                                 )\n",
    "\n",
    "X_test_norm_textblob_header, \\\n",
    "y_test_norm_textblob_header, \\\n",
    "_ = minmax_scale_textblob_header(X_test_textblob_header,\n",
    "                                 y_test_textblob_header,\n",
    "                                 normalizers_textblob_header=normalizers_textblob_header\n",
    "                                 )\n",
    "\n",
    "# Creating target (y) and \"windows\" (X) for modeling\n",
    "TIME_WINDOW_textblob_header = 30\n",
    "FORECAST_DISTANCE_textblob_header = 5\n",
    "\n",
    "segmenter_textblob_header = SegmentXYForecast(width=TIME_WINDOW_textblob_header,\n",
    "                                              step=1,\n",
    "                                              y_func=last,\n",
    "                                              forecast=FORECAST_DISTANCE_textblob_header\n",
    "                                              )\n",
    "\n",
    "X_train_rolled_textblob_header, \\\n",
    "y_train_rolled_textblob_header, \\\n",
    "_ = segmenter_textblob_header.fit_transform([X_train_norm_textblob_header.values],\n",
    "                                            [y_train_norm_textblob_header.flatten()]\n",
    "                                            )\n",
    "\n",
    "X_valid_rolled_textblob_header, \\\n",
    "y_valid_rolled_textblob_header, \\\n",
    "_ = segmenter_textblob_header.fit_transform([X_valid_norm_textblob_header.values],\n",
    "                                            [y_valid_norm_textblob_header.flatten()]\n",
    "                                            )\n",
    "\n",
    "X_test_rolled_textblob_header, \\\n",
    "y_test_rolled_textblob_header, \\\n",
    "_ = segmenter_textblob_header.fit_transform([X_test_norm_textblob_header.values],\n",
    "                                            [y_test_norm_textblob_header.flatten()]\n",
    "                                            )\n",
    "\n",
    "shape_textblob_header = X_train_rolled_textblob_header.shape\n",
    "X_train_flattened_textblob_header = X_train_rolled_textblob_header.reshape(shape_textblob_header[0],\n",
    "                                                                           shape_textblob_header[1]*shape_textblob_header[2]\n",
    "                                                                           )\n",
    "\n",
    "X_train_flattened_textblob_header.shape\n",
    "shape_textblob_header = X_valid_rolled_textblob_header.shape\n",
    "X_valid_flattened = X_valid_rolled_textblob_header.reshape(shape_textblob_header[0],\n",
    "                                                           shape_textblob_header[1]*shape_textblob_header[2]\n",
    "                                                           )\n",
    "\n",
    "# Random Forest\n",
    "N_ESTIMATORS_textblob_header = 30\n",
    "RANDOM_STATE_textblob_header = 452543634\n",
    "\n",
    "RF_base_model_textblob_header = RandomForestRegressor(random_state=RANDOM_STATE_textblob_header,\n",
    "                                                      n_estimators=N_ESTIMATORS_textblob_header,\n",
    "                                                      n_jobs=-1,\n",
    "                                                      verbose=100\n",
    "                                                      )\n",
    "\n",
    "RF_base_model_textblob_header.fit(X_train_flattened_textblob_header, y_train_rolled_textblob_header)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_textblob_header = RF_base_model_textblob_header.predict(X_valid_flattened)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "rms_base_textblob_header = sqrt(mean_squared_error(y_valid_rolled_textblob_header,\n",
    "                                                   RF_base_model_predictions_textblob_header\n",
    "                                                   )\n",
    "                                )\n",
    "\n",
    "print(\"Root mean squared error on valid:\",rms_base_textblob_header)\n",
    "print(\"Root mean squared error on valid inverse transformed from normalization:\",normalizers_textblob_header[\"OPEN\"]\n",
    "      .inverse_transform(np.array([rms_base_textblob_header]).reshape(-1, 1)))\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_textblob_header = normalizers_textblob_header['OPEN']\\\n",
    "                                          .inverse_transform(np.array(RF_base_model_predictions_textblob_header).reshape(-1, 1))\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "new_df_vader_content = concatenate_dataframe[['OPEN',\n",
    "                                              'HIGH',\n",
    "                                              'LOW',\n",
    "                                              'CLOSE',\n",
    "                                              'VOLUME',\n",
    "                                              'compound_vader_articel_content']]\n",
    "\n",
    "new_df_vader_content = new_df_vader_content.fillna(0)\n",
    "# new_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'compound_vader_articel_content'].astype(np.float64)\n",
    "# print(new_df)\n",
    "\n",
    "# train, valid, test split\n",
    "valid_test_size_split_vader_content = 0.1\n",
    "\n",
    "X_train_vader_content, \\\n",
    "X_else_vader_content, \\\n",
    "y_train_vader_content, \\\n",
    "y_else_vader_content = train_test_split(new_df_vader_content,\n",
    "                                        new_df_vader_content['OPEN'],\n",
    "                                        test_size=valid_test_size_split_vader_content*2,\n",
    "                                        shuffle=False)\n",
    "\n",
    "X_valid_vader_content, \\\n",
    "X_test_vader_content, \\\n",
    "y_valid_vader_content, \\\n",
    "y_test_vader_content = train_test_split(X_else_vader_content,\n",
    "                                        y_else_vader_content,\n",
    "                                        test_size=0.5,\n",
    "                                        shuffle=False)\n",
    "#print(y_else)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "# normalize data\n",
    "def minmax_scale_vader_content(df_x, series_y, normalizers_vader_content = None):\n",
    "    features_to_minmax = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'compound_vader_articel_content']\n",
    "\n",
    "    if not normalizers_vader_content:\n",
    "        normalizers_vader_content = {}\n",
    "\n",
    "    for feat in features_to_minmax:\n",
    "        if feat not in normalizers_vader_content:\n",
    "            normalizers_vader_content[feat] = MinMaxScaler()\n",
    "            normalizers_vader_content[feat].fit(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "        df_x[feat] = normalizers_vader_content[feat].transform(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "    series_y = normalizers_vader_content['OPEN'].transform(series_y.values.reshape(-1, 1))\n",
    "\n",
    "    return df_x, series_y, normalizers_vader_content\n",
    "\n",
    "X_train_norm_vader_content, \\\n",
    "y_train_norm_vader_content, \\\n",
    "normalizers_vader_content = minmax_scale_vader_content(X_train_vader_content,\n",
    "                                                       y_train_vader_content\n",
    "                                                       )\n",
    "\n",
    "X_valid_norm_vader_content, \\\n",
    "y_valid_norm_vader_content, \\\n",
    "_ = minmax_scale_vader_content(X_valid_vader_content,\n",
    "                               y_valid_vader_content,\n",
    "                               normalizers_vader_content=normalizers_vader_content\n",
    "                               )\n",
    "\n",
    "X_test_norm_vader_content, \\\n",
    "y_test_norm_vader_content, \\\n",
    "_ = minmax_scale_vader_content(X_test_vader_content,\n",
    "                               y_test_vader_content,\n",
    "                               normalizers_vader_content=normalizers_vader_content\n",
    "                               )\n",
    "\n",
    "# Creating target (y) and \"windows\" (X) for modeling\n",
    "TIME_WINDOW_vader_content = 30\n",
    "FORECAST_DISTANCE_vader_content = 5\n",
    "\n",
    "segmenter_vader_content = SegmentXYForecast(width=TIME_WINDOW_vader_content,\n",
    "                                            step=1,\n",
    "                                            y_func=last,\n",
    "                                            forecast=FORECAST_DISTANCE_vader_content\n",
    "                                            )\n",
    "\n",
    "X_train_rolled_vader_content, \\\n",
    "y_train_rolled_vader_content, \\\n",
    "_ = segmenter_vader_content.fit_transform([X_train_norm_vader_content.values],\n",
    "                                          [y_train_norm_vader_content.flatten()]\n",
    "                                          )\n",
    "\n",
    "X_valid_rolled_vader_content, \\\n",
    "y_valid_rolled_vader_content, \\\n",
    "_ = segmenter_vader_content.fit_transform([X_valid_norm_vader_content.values],\n",
    "                                          [y_valid_norm_vader_content.flatten()]\n",
    "                                          )\n",
    "\n",
    "X_test_rolled_vader_content, \\\n",
    "y_test_rolled_vader_content, \\\n",
    "_ = segmenter_vader_content.fit_transform([X_test_norm_vader_content.values],\n",
    "                                          [y_test_norm_vader_content.flatten()]\n",
    "                                          )\n",
    "\n",
    "shape_vader_content = X_train_rolled_vader_content.shape\n",
    "X_train_flattened_vader_content = X_train_rolled_vader_content.reshape(shape_vader_content[0],\n",
    "                                                                       shape_vader_content[1]*shape_vader_content[2]\n",
    "                                                                       )\n",
    "\n",
    "X_train_flattened_vader_content.shape\n",
    "shape_vader_content = X_valid_rolled_vader_content.shape\n",
    "X_valid_flattened = X_valid_rolled_vader_content.reshape(shape_vader_content[0],\n",
    "                                                         shape_vader_content[1]*shape_vader_content[2]\n",
    "                                                         )\n",
    "\n",
    "# Random Forest\n",
    "N_ESTIMATORS_vader_content = 30\n",
    "RANDOM_STATE_vader_content = 452543634\n",
    "\n",
    "RF_base_model_vader_content = RandomForestRegressor(random_state=RANDOM_STATE_vader_content,\n",
    "                                                    n_estimators=N_ESTIMATORS_vader_content,\n",
    "                                                    n_jobs=-1,\n",
    "                                                    verbose=100\n",
    "                                                    )\n",
    "\n",
    "RF_base_model_vader_content.fit(X_train_flattened_vader_content, y_train_rolled_vader_content)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_vader_content = RF_base_model_vader_content.predict(X_valid_flattened)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "rms_base_vader_content = sqrt(mean_squared_error(y_valid_rolled_vader_content,\n",
    "                                                 RF_base_model_predictions_vader_content\n",
    "                                                 )\n",
    "                              )\n",
    "\n",
    "print(\"Root mean squared error on valid:\",rms_base_vader_content)\n",
    "print(\"Root mean squared error on valid inverse transformed from normalization:\",normalizers_vader_content[\"OPEN\"]\n",
    "      .inverse_transform(np.array([rms_base_textblob_content]).reshape(-1, 1)))\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_vader_content = normalizers_vader_content['OPEN']\\\n",
    "                                          .inverse_transform(np.array(RF_base_model_predictions_vader_content).reshape(-1, 1))\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "new_df_vader_header = concatenate_dataframe[['OPEN',\n",
    "                                             'HIGH',\n",
    "                                             'LOW',\n",
    "                                             'CLOSE',\n",
    "                                             'VOLUME',\n",
    "                                             'compound_vader_header']]\n",
    "\n",
    "new_df_vader_header = new_df_vader_header.fillna(0)\n",
    "# new_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'compound_vader_header']].astype(np.float64)\n",
    "# print(new_df)\n",
    "\n",
    "# train, valid, test split\n",
    "valid_test_size_split_vader_header = 0.1\n",
    "\n",
    "X_train_vader_header, \\\n",
    "X_else_vader_header, \\\n",
    "y_train_vader_header, \\\n",
    "y_else_vader_header = train_test_split(new_df_vader_header,\n",
    "                                       new_df_vader_header['OPEN'],\n",
    "                                       test_size=valid_test_size_split_vader_header*2,\n",
    "                                       shuffle=False)\n",
    "\n",
    "X_valid_vader_header, \\\n",
    "X_test_vader_header, \\\n",
    "y_valid_vader_header, \\\n",
    "y_test_vader_header = train_test_split(X_else_vader_header,\n",
    "                                       y_else_vader_header,\n",
    "                                       test_size=0.5,\n",
    "                                       shuffle=False)\n",
    "#print(y_else)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "# normalize data\n",
    "def minmax_scale_vader_header(df_x, series_y, normalizers_vader_header = None):\n",
    "    features_to_minmax = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'compound_vader_header']\n",
    "\n",
    "    if not normalizers_vader_header:\n",
    "        normalizers_vader_header = {}\n",
    "\n",
    "    for feat in features_to_minmax:\n",
    "        if feat not in normalizers_vader_header:\n",
    "            normalizers_vader_header[feat] = MinMaxScaler()\n",
    "            normalizers_vader_header[feat].fit(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "        df_x[feat] = normalizers_vader_header[feat].transform(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "    series_y = normalizers_vader_header['OPEN'].transform(series_y.values.reshape(-1, 1))\n",
    "\n",
    "    return df_x, series_y, normalizers_vader_header\n",
    "\n",
    "X_train_norm_vader_header, \\\n",
    "y_train_norm_vader_header, \\\n",
    "normalizers_vader_header = minmax_scale_vader_header(X_train_vader_header,\n",
    "                                                     y_train_vader_header\n",
    "                                                     )\n",
    "\n",
    "X_valid_norm_vader_header, \\\n",
    "y_valid_norm_vader_header, \\\n",
    "_ = minmax_scale_vader_header(X_valid_vader_header,\n",
    "                              y_valid_vader_header,\n",
    "                              normalizers_vader_header=normalizers_vader_header\n",
    "                              )\n",
    "\n",
    "X_test_norm_vader_header, \\\n",
    "y_test_norm_vader_header, \\\n",
    "_ = minmax_scale_vader_header(X_test_vader_header,\n",
    "                              y_test_vader_header,\n",
    "                              normalizers_vader_header=normalizers_vader_header\n",
    "                              )\n",
    "\n",
    "# Creating target (y) and \"windows\" (X) for modeling\n",
    "TIME_WINDOW_vader_header = 30\n",
    "FORECAST_DISTANCE_vader_header = 5\n",
    "\n",
    "segmenter_vader_header = SegmentXYForecast(width=TIME_WINDOW_vader_header,\n",
    "                                           step=1,\n",
    "                                           y_func=last,\n",
    "                                           forecast=FORECAST_DISTANCE_vader_header\n",
    "                                           )\n",
    "\n",
    "X_train_rolled_vader_header, \\\n",
    "y_train_rolled_vader_header, \\\n",
    "_ = segmenter_vader_header.fit_transform([X_train_norm_vader_header.values],\n",
    "                                         [y_train_norm_vader_header.flatten()]\n",
    "                                         )\n",
    "\n",
    "X_valid_rolled_vader_header, \\\n",
    "y_valid_rolled_vader_header, \\\n",
    "_ = segmenter_vader_header.fit_transform([X_valid_norm_vader_header.values],\n",
    "                                         [y_valid_norm_vader_header.flatten()]\n",
    "                                         )\n",
    "\n",
    "X_test_rolled_vader_header, \\\n",
    "y_test_rolled_vader_header, \\\n",
    "_ = segmenter_vader_header.fit_transform([X_test_norm_vader_header.values],\n",
    "                                         [y_test_norm_vader_header.flatten()]\n",
    "                                         )\n",
    "\n",
    "shape_vader_header = X_train_rolled_vader_header.shape\n",
    "X_train_flattened_vader_header = X_train_rolled_vader_header.reshape(shape_vader_header[0],\n",
    "                                                                     shape_vader_header[1]*shape_vader_header[2]\n",
    "                                                                     )\n",
    "\n",
    "X_train_flattened_vader_header.shape\n",
    "shape_vader_header = X_valid_rolled_vader_header.shape\n",
    "X_valid_flattened = X_valid_rolled_vader_header.reshape(shape_vader_header[0],\n",
    "                                                        shape_vader_header[1]*shape_vader_header[2]\n",
    "                                                        )\n",
    "\n",
    "# Random Forest\n",
    "N_ESTIMATORS_vader_header = 30\n",
    "RANDOM_STATE_vader_header = 452543634\n",
    "\n",
    "RF_base_model_vader_header = RandomForestRegressor(random_state=RANDOM_STATE_vader_header,\n",
    "                                                   n_estimators=N_ESTIMATORS_vader_header,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   verbose=100\n",
    "                                                   )\n",
    "\n",
    "RF_base_model_vader_header.fit(X_train_flattened_vader_header, y_train_rolled_vader_header)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_vader_header = RF_base_model_vader_header.predict(X_valid_flattened)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "rms_base_vader_header = sqrt(mean_squared_error(y_valid_rolled_vader_header,\n",
    "                                                RF_base_model_predictions_vader_header\n",
    "                                                )\n",
    "                             )\n",
    "\n",
    "print(\"Root mean squared error on valid:\", rms_base_vader_header)\n",
    "print(\"Root mean squared error on valid inverse transformed from normalization:\", normalizers_vader_header[\"OPEN\"]\n",
    "      .inverse_transform(np.array([rms_base_vader_header]).reshape(-1, 1)))\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_vader_header = normalizers_vader_header['OPEN']\\\n",
    "                                          .inverse_transform(np.array(RF_base_model_predictions_vader_header).reshape(-1, 1))\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "new_df_without_semantics = concatenate_dataframe[['OPEN',\n",
    "                                                  'HIGH',\n",
    "                                                  'LOW',\n",
    "                                                  'CLOSE',\n",
    "                                                  'VOLUME']]\n",
    "\n",
    "new_df_without_semantics = new_df_without_semantics.fillna(0)\n",
    "# new_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME']].astype(np.float64)\n",
    "# print(new_df)\n",
    "\n",
    "# train, valid, test split\n",
    "valid_test_size_split_without_semantics = 0.1\n",
    "\n",
    "X_train_without_semantics, \\\n",
    "X_else_without_semantics, \\\n",
    "y_train_without_semantics, \\\n",
    "y_else_without_semantics = train_test_split(new_df_without_semantics,\n",
    "                                            new_df_without_semantics['OPEN'],\n",
    "                                            test_size=valid_test_size_split_without_semantics*2,\n",
    "                                            shuffle=False)\n",
    "\n",
    "X_valid_without_semantics, \\\n",
    "X_test_without_semantics, \\\n",
    "y_valid_without_semantics, \\\n",
    "y_test_without_semantics = train_test_split(X_else_without_semantics,\n",
    "                                            y_else_without_semantics,\n",
    "                                            test_size=0.5,\n",
    "                                            shuffle=False)\n",
    "#print(y_else)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "# normalize data\n",
    "def minmax_scale_without_semantics(df_x, series_y, normalizers_without_semantics = None):\n",
    "    features_to_minmax = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME']\n",
    "\n",
    "    if not normalizers_without_semantics:\n",
    "        normalizers_without_semantics = {}\n",
    "\n",
    "    for feat in features_to_minmax:\n",
    "        if feat not in normalizers_without_semantics:\n",
    "            normalizers_without_semantics[feat] = MinMaxScaler()\n",
    "            normalizers_without_semantics[feat].fit(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "        df_x[feat] = normalizers_without_semantics[feat].transform(df_x[feat].values.reshape(-1, 1))\n",
    "\n",
    "    series_y = normalizers_without_semantics['OPEN'].transform(series_y.values.reshape(-1, 1))\n",
    "\n",
    "    return df_x, series_y, normalizers_without_semantics\n",
    "\n",
    "X_train_norm_without_semantics, \\\n",
    "y_train_norm_without_semantics, \\\n",
    "normalizers_without_semantics = minmax_scale_without_semantics(X_train_without_semantics,\n",
    "                                                               y_train_without_semantics\n",
    "                                                               )\n",
    "\n",
    "X_valid_norm_without_semantics, \\\n",
    "y_valid_norm_without_semantics, \\\n",
    "_ = minmax_scale_without_semantics(X_valid_without_semantics,\n",
    "                                   y_valid_without_semantics,\n",
    "                                   normalizers_without_semantics=normalizers_without_semantics\n",
    "                                   )\n",
    "\n",
    "X_test_norm_without_semantics, \\\n",
    "y_test_norm_without_semantics, \\\n",
    "_ = minmax_scale_without_semantics(X_test_without_semantics,\n",
    "                                   y_test_without_semantics,\n",
    "                                   normalizers_without_semantics=normalizers_without_semantics\n",
    "                                   )\n",
    "\n",
    "# Creating target (y) and \"windows\" (X) for modeling\n",
    "TIME_WINDOW_without_semantics = 30\n",
    "FORECAST_DISTANCE_without_semantics = 5\n",
    "\n",
    "segmenter_without_semantics = SegmentXYForecast(width=TIME_WINDOW_without_semantics,\n",
    "                                                step=1,\n",
    "                                                y_func=last,\n",
    "                                                forecast=FORECAST_DISTANCE_without_semantics\n",
    "                                                )\n",
    "\n",
    "X_train_rolled_without_semantics, \\\n",
    "y_train_rolled_without_semantics, \\\n",
    "_ = segmenter_without_semantics.fit_transform([X_train_norm_without_semantics.values],\n",
    "                                              [y_train_norm_without_semantics.flatten()]\n",
    "                                              )\n",
    "\n",
    "X_valid_rolled_without_semantics, \\\n",
    "y_valid_rolled_without_semantics, \\\n",
    "_ = segmenter_without_semantics.fit_transform([X_valid_norm_without_semantics.values],\n",
    "                                              [y_valid_norm_without_semantics.flatten()]\n",
    "                                              )\n",
    "\n",
    "X_test_rolled_without_semantics, \\\n",
    "y_test_rolled_without_semantics, \\\n",
    "_ = segmenter_without_semantics.fit_transform([X_test_norm_without_semantics.values],\n",
    "                                              [y_test_norm_without_semantics.flatten()]\n",
    "                                              )\n",
    "\n",
    "shape_without_semantics = X_train_rolled_without_semantics.shape\n",
    "X_train_flattened_without_semantics = X_train_rolled_without_semantics.reshape(shape_without_semantics[0],\n",
    "                                                                               shape_without_semantics[1]*shape_without_semantics[2]\n",
    "                                                                               )\n",
    "\n",
    "X_train_flattened_without_semantics.shape\n",
    "shape_without_semantics = X_valid_rolled_without_semantics.shape\n",
    "X_valid_flattened = X_valid_rolled_without_semantics.reshape(shape_without_semantics[0],\n",
    "                                                             shape_without_semantics[1]*shape_without_semantics[2]\n",
    "                                                             )\n",
    "\n",
    "# Random Forest\n",
    "N_ESTIMATORS_without_semantics = 30\n",
    "RANDOM_STATE_without_semantics = 452543634\n",
    "\n",
    "RF_base_model_without_semantics = RandomForestRegressor(random_state=RANDOM_STATE_without_semantics,\n",
    "                                                        n_estimators=N_ESTIMATORS_without_semantics,\n",
    "                                                        n_jobs=-1,\n",
    "                                                        verbose=100\n",
    "                                                        )\n",
    "\n",
    "RF_base_model_without_semantics.fit(X_train_flattened_without_semantics, y_train_rolled_without_semantics)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_without_semantics = RF_base_model_without_semantics.predict(X_valid_flattened)\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "rms_base_without_semantics = sqrt(mean_squared_error(y_valid_rolled_without_semantics,\n",
    "                                                     RF_base_model_predictions_without_semantics\n",
    "                                                     )\n",
    "                                  )\n",
    "\n",
    "print(\"Root mean squared error on valid:\", rms_base_without_semantics)\n",
    "print(\"Root mean squared error on valid inverse transformed from normalization:\", normalizers_without_semantics[\"OPEN\"]\n",
    "      .inverse_transform(np.array([rms_base_without_semantics]).reshape(-1, 1)))\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "RF_base_model_predictions_without_semantics = normalizers_without_semantics['OPEN']\\\n",
    "                                          .inverse_transform(np.array(RF_base_model_predictions_without_semantics).reshape(-1, 1))\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "print(' ')\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(' ')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(RF_base_model_predictions_flair_content, color='green', label='Predicted Peugeot Stock Price with flair content analysis')\n",
    "plt.plot(RF_base_model_predictions_flair_header, color='red', label='Predicted Peugeot Stock Price with flair header analysis')\n",
    "plt.plot(RF_base_model_predictions_textblob_content, color='orange', label='Predicted Peugeot Stock Price with textblob content analysis')\n",
    "plt.plot(RF_base_model_predictions_textblob_header, color='blue', label='Predicted Peugeot Stock Price with textblob header analysis')\n",
    "plt.plot(RF_base_model_predictions_vader_content, color='cyan', label='Predicted Peugeot Stock Price with vader content analysis')\n",
    "plt.plot(RF_base_model_predictions_vader_header, color='magenta', label='Predicted Peugeot Stock Price with vader header analysis')\n",
    "plt.plot(RF_base_model_predictions_without_semantics, color='yellow', label='Predicted Peugeot Stock Price without semantics analysis')\n",
    "plt.title('Peugeot Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Peugeot Stock Price')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.005), borderaxespad=8)\n",
    "\n",
    "date_today = str(datetime.now().strftime(\"%Y%m%d\"))\n",
    "plt.savefig(r'C:\\Users\\victo\\Master_Thesis\\stockprice_prediction\\RandomForest_base_model\\peugeot\\daily\\prediction_peugeot_with_semantics_' + date_today + '.png',\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=100,\n",
    "            pad_inches=1.5)\n",
    "plt.show()\n",
    "print('Run is finished and plot is saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
